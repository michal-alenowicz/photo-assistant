{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3dea29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vision.py\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e00f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_VISION_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_VISION_KEY\")\n",
    "client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b4588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_bytes(image_bytes):\n",
    "    \"\"\"Return dict: captions, tags (with confidence), ocr_text (if any).\"\"\"\n",
    "    from io import BytesIO\n",
    "    stream = BytesIO(image_bytes)\n",
    "    # describe\n",
    "    desc = client.describe_image_in_stream(stream, max_candidates=3)\n",
    "    captions = [{\"text\": c.text, \"confidence\": c.confidence} for c in (desc.captions or [])]\n",
    "    # Reset stream pointer\n",
    "    stream.seek(0)\n",
    "    # tags\n",
    "    tags_res = client.tag_image_in_stream(stream)\n",
    "    tags = [{\"name\": t.name, \"confidence\": t.confidence} for t in (tags_res.tags or [])]\n",
    "    # OCR (read)\n",
    "    stream.seek(0)\n",
    "    ocr = client.read_in_stream(stream, raw=True)\n",
    "    # azure read is async â€” get result\n",
    "    operation_location_remote = ocr.headers[\"Operation-Location\"]\n",
    "    operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "    import time\n",
    "    while True:\n",
    "        result = client.get_read_result(operation_id)\n",
    "        if result.status not in ['notStarted', 'running']:\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "    ocr_text = \"\"\n",
    "    if result.status == 'succeeded':\n",
    "        for page in result.analyze_result.read_results:\n",
    "            for line in page.lines:\n",
    "                ocr_text += line.text + \"\\n\"\n",
    "    return {\"captions\": captions, \"tags\": tags, \"ocr_text\": ocr_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af9bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': [{'text': 'a group of people holding signs', 'confidence': 0.6494011878967285}], 'tags': [{'name': 'clothing', 'confidence': 0.9988632798194885}, {'name': 'human face', 'confidence': 0.9978727102279663}, {'name': 'person', 'confidence': 0.9968821406364441}, {'name': 'woman', 'confidence': 0.9683936834335327}, {'name': 'text', 'confidence': 0.956762969493866}, {'name': 'man', 'confidence': 0.9565277099609375}, {'name': 'smile', 'confidence': 0.9443103075027466}, {'name': 'newspaper', 'confidence': 0.8428946137428284}, {'name': 'outdoor', 'confidence': 0.8321356773376465}, {'name': 'group', 'confidence': 0.7874609231948853}, {'name': 'sign', 'confidence': 0.7766597867012024}, {'name': 'people', 'confidence': 0.7492111921310425}], 'ocr_text': 'TRUMI\\nTRUMP\\nWe WeTAFAGAIN!\\nMAKE AMERICA GREAT AGAIN\\nTRUMP\\nthe silent majority\\nMEINERICA GREAT AGAIN!\\nT\\nSTANDS WITH\\nTRUMP\\nSUME\\nNEM\\nWent may\\nRUMP\\nS W\\nAMERI GREAT AGAIN!\\nTR\\nSTAN\\nTRUMP\\nthe site\\nRUI\\nARE AMERICA GREAT AGAIN\\nSTAN\\nWITH\\n'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample_images\\\\sample01.jpg\",\"rb\") as f:\n",
    "    res = analyze_image_bytes(f.read())\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38f4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': [{'text': 'a group of jockeys racing horses', 'confidence': 0.5538452863693237}], 'tags': [{'name': 'horse', 'confidence': 0.9770833253860474}, {'name': 'stadium', 'confidence': 0.9752413034439087}, {'name': 'outdoor', 'confidence': 0.9523265957832336}, {'name': 'building', 'confidence': 0.9427610039710999}, {'name': 'rein', 'confidence': 0.9391779899597168}, {'name': 'bridle', 'confidence': 0.9323909282684326}, {'name': 'stallion', 'confidence': 0.9239025712013245}, {'name': 'horse tack', 'confidence': 0.9214749336242676}, {'name': 'horse supplies', 'confidence': 0.9210265874862671}, {'name': 'flat racing', 'confidence': 0.9156216979026794}, {'name': 'halter', 'confidence': 0.9028061628341675}, {'name': 'mare', 'confidence': 0.8987149596214294}, {'name': 'equestrianism', 'confidence': 0.8742722868919373}, {'name': 'saddle', 'confidence': 0.8724848031997681}, {'name': 'horse racing', 'confidence': 0.870876133441925}, {'name': 'jockey', 'confidence': 0.8687554597854614}, {'name': 'animal sports', 'confidence': 0.8578435778617859}, {'name': 'grass', 'confidence': 0.8521130084991455}, {'name': 'mane', 'confidence': 0.8485252857208252}, {'name': 'racing', 'confidence': 0.8210968375205994}, {'name': 'person', 'confidence': 0.6902799606323242}, {'name': 'riding', 'confidence': 0.6800144910812378}, {'name': 'people', 'confidence': 0.5848963856697083}, {'name': 'track', 'confidence': 0.5521560311317444}], 'ocr_text': 'Torei\\nHELIOS EXPRESS\\nSRISIG\\nTONO REF,\\nO\\n'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample_images\\\\sample02.jpg\",\"rb\") as f:\n",
    "    res = analyze_image_bytes(f.read())\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photo-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
