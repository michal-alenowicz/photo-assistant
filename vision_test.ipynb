{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3dea29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vision.py\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "import os\n",
    "from io import BytesIO\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e00f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_VISION_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_VISION_KEY\")\n",
    "client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b4588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_bytes(image_bytes):\n",
    "    \"\"\"Return dict: captions, tags (with confidence), ocr_text (if any).\"\"\"\n",
    "    from io import BytesIO\n",
    "    stream = BytesIO(image_bytes)\n",
    "    # describe\n",
    "    desc = client.describe_image_in_stream(stream, max_candidates=3)\n",
    "    captions = [{\"text\": c.text, \"confidence\": c.confidence} for c in (desc.captions or [])]\n",
    "    # Reset stream pointer\n",
    "    stream.seek(0)\n",
    "    # tags\n",
    "    tags_res = client.tag_image_in_stream(stream)\n",
    "    tags = [{\"name\": t.name, \"confidence\": t.confidence} for t in (tags_res.tags or [])]\n",
    "    # OCR (read)\n",
    "    stream.seek(0)\n",
    "    ocr = client.read_in_stream(stream, raw=True)\n",
    "    # azure read is async — get result\n",
    "    operation_location_remote = ocr.headers[\"Operation-Location\"]\n",
    "    operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "    import time\n",
    "    while True:\n",
    "        result = client.get_read_result(operation_id)\n",
    "        if result.status not in ['notStarted', 'running']:\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "    ocr_text = \"\"\n",
    "    if result.status == 'succeeded':\n",
    "        for page in result.analyze_result.read_results:\n",
    "            for line in page.lines:\n",
    "                ocr_text += line.text + \"\\n\"\n",
    "    return {\"captions\": captions, \"tags\": tags, \"ocr_text\": ocr_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6aa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_bytes3(image_bytes: bytes) -> dict:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - captions: list of {text, confidence}\n",
    "      - tags: list of {name, confidence}\n",
    "      - ocr_text: extracted text\n",
    "      - landmarks: list of detected landmarks\n",
    "      - celebrities: list of detected celebrities\n",
    "    \"\"\"\n",
    "\n",
    "    stream = BytesIO(image_bytes)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # DESCRIBE IMAGE (captions)\n",
    "    # --------------------------------------------------------\n",
    "    desc = client.describe_image_in_stream(stream, max_candidates=3)\n",
    "    captions = [\n",
    "        {\"text\": c.text, \"confidence\": c.confidence}\n",
    "        for c in (desc.captions or [])\n",
    "    ]\n",
    "\n",
    "    # Reset\n",
    "    stream.seek(0)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # TAGS\n",
    "    # --------------------------------------------------------\n",
    "    tag_res = client.tag_image_in_stream(stream)\n",
    "    tags = [\n",
    "        {\"name\": t.name, \"confidence\": t.confidence}\n",
    "        for t in (tag_res.tags or [])\n",
    "    ]\n",
    "\n",
    "    # Reset\n",
    "    stream.seek(0)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # OCR (Read API — async)\n",
    "    # --------------------------------------------------------\n",
    "    ocr_raw = client.read_in_stream(stream, raw=True)\n",
    "    op_location = ocr_raw.headers[\"Operation-Location\"]\n",
    "    op_id = op_location.split(\"/\")[-1]\n",
    "\n",
    "    # Poll the result\n",
    "    while True:\n",
    "        read_res = client.get_read_result(op_id)\n",
    "        if read_res.status not in [\"notStarted\", \"running\"]:\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    ocr_text = \"\"\n",
    "    if read_res.status == OperationStatusCodes.succeeded:\n",
    "        for page in read_res.analyze_result.read_results:\n",
    "            for line in page.lines:\n",
    "                ocr_text += line.text + \"\\n\"\n",
    "\n",
    "    # Reset\n",
    "    stream.seek(0)\n",
    "\n",
    "    # # --------------------------------------------------------\n",
    "    # # CELEBRITY DETECTION  (Domain = \"celebrities\")\n",
    "    # # --------------------------------------------------------\n",
    "    # celeb_res = client.analyze_image_by_domain_in_stream(\n",
    "    #     \"celebrities\",\n",
    "    #     stream\n",
    "    # )\n",
    "\n",
    "    # celebrities = []\n",
    "    # if celeb_res and celeb_res.result:\n",
    "    #     for person in celeb_res.result.get(\"celebrities\", []):\n",
    "    #         celebrities.append({\n",
    "    #             \"name\": person.get(\"name\"),\n",
    "    #             \"confidence\": person.get(\"confidence\"),\n",
    "    #             \"faceRectangle\": person.get(\"faceRectangle\")\n",
    "    #         })\n",
    "\n",
    "    # # Reset\n",
    "    # stream.seek(0)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # LANDMARK DETECTION  (Domain = \"landmarks\")\n",
    "    # --------------------------------------------------------\n",
    "    land_res = client.analyze_image_by_domain_in_stream(\n",
    "        \"landmarks\",\n",
    "        stream\n",
    "    )\n",
    "\n",
    "    landmarks = []\n",
    "    if land_res and land_res.result:\n",
    "        for lm in land_res.result.get(\"landmarks\", []):\n",
    "            landmarks.append({\n",
    "                \"name\": lm.get(\"name\"),\n",
    "                \"confidence\": lm.get(\"confidence\")\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"captions\": captions,\n",
    "        \"tags\": tags,\n",
    "        \"ocr_text\": ocr_text,\n",
    "        #\"celebrities\": celebrities,\n",
    "        \"landmarks\": landmarks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af9bc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': [{'text': 'a group of people holding signs', 'confidence': 0.6494020819664001}], 'tags': [{'name': 'clothing', 'confidence': 0.9988632798194885}, {'name': 'human face', 'confidence': 0.9978727102279663}, {'name': 'person', 'confidence': 0.9968821406364441}, {'name': 'woman', 'confidence': 0.9683936834335327}, {'name': 'text', 'confidence': 0.956762969493866}, {'name': 'man', 'confidence': 0.9565277099609375}, {'name': 'smile', 'confidence': 0.9443103075027466}, {'name': 'newspaper', 'confidence': 0.8428946137428284}, {'name': 'outdoor', 'confidence': 0.8321356773376465}, {'name': 'group', 'confidence': 0.7874609231948853}, {'name': 'sign', 'confidence': 0.7766597867012024}, {'name': 'people', 'confidence': 0.7492111921310425}], 'ocr_text': 'TRUMI\\nTRUMP\\nWe WeTAFAGAIN!\\nMAKE AMERICA GREAT AGAIN\\nTRUMP\\nthe silent majority\\nMEINERICA GREAT AGAIN!\\nT\\nSTANDS WITH\\nTRUMP\\nSUME\\nNEM\\nWent may\\nRUMP\\nS W\\nAMERI GREAT AGAIN!\\nTR\\nSTAN\\nTRUMP\\nthe site\\nRUI\\nARE AMERICA GREAT AGAIN\\nSTAN\\nWITH\\n', 'landmarks': []}\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample_images\\\\sample01.jpg\",\"rb\") as f:\n",
    "    res = analyze_image_bytes3(f.read())\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e38f4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': [{'text': 'a group of jockeys racing horses', 'confidence': 0.5538452863693237}], 'tags': [{'name': 'horse', 'confidence': 0.9770833253860474}, {'name': 'stadium', 'confidence': 0.9752413034439087}, {'name': 'outdoor', 'confidence': 0.9523265957832336}, {'name': 'building', 'confidence': 0.9427610039710999}, {'name': 'rein', 'confidence': 0.9391779899597168}, {'name': 'bridle', 'confidence': 0.9323909282684326}, {'name': 'stallion', 'confidence': 0.9239025712013245}, {'name': 'horse tack', 'confidence': 0.9214749336242676}, {'name': 'horse supplies', 'confidence': 0.9210265874862671}, {'name': 'flat racing', 'confidence': 0.9156216979026794}, {'name': 'halter', 'confidence': 0.9028061628341675}, {'name': 'mare', 'confidence': 0.8987149596214294}, {'name': 'equestrianism', 'confidence': 0.8742722868919373}, {'name': 'saddle', 'confidence': 0.8724848031997681}, {'name': 'horse racing', 'confidence': 0.870876133441925}, {'name': 'jockey', 'confidence': 0.8687554597854614}, {'name': 'animal sports', 'confidence': 0.8578435778617859}, {'name': 'grass', 'confidence': 0.8521130084991455}, {'name': 'mane', 'confidence': 0.8485252857208252}, {'name': 'racing', 'confidence': 0.8210968375205994}, {'name': 'person', 'confidence': 0.6902799606323242}, {'name': 'riding', 'confidence': 0.6800144910812378}, {'name': 'people', 'confidence': 0.5848963856697083}, {'name': 'track', 'confidence': 0.5521560311317444}], 'ocr_text': 'Torei\\nHELIOS EXPRESS\\nSRISIG\\nTONO REF,\\nO\\n', 'landmarks': []}\n"
     ]
    }
   ],
   "source": [
    "with open(\"sample_images\\\\sample02.jpg\",\"rb\") as f:\n",
    "    res = analyze_image_bytes3(f.read())\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photo-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
